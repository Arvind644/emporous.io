---
title: "Universal Object Reference"
linkTitle: "Overview"
weight: 1
description: >
  "Everything is an object" - @afflom
---

= Universal Object Reference
:toc:
:toclevels: 3
:sectnumlevels: 3

== Data is Exploding
The storage landscape of today is in a transformative phase. From less than 14 Billion IoT devices by the end of 2021, projections anticipate breaking 30 billion IoT devices as soon as 2025. The whole globe is buzzing to life in digital terms, generating more raw data and more ways of using and understanding this new flood of information than ever.

Accelerated by things like IoT and 5G, even new content creator cultures are evolving into existence at a break neck pace. Attempts to comprehend all of the new data sources and content types truly test the limits of the human imaginative ability.

Our digital economy has taken notice too. Businesses of every kind are learning that data drives commerce. Data is becoming the single most valuable commodity on the internet. Ironically, the understanding of data, the storage of data, and the distribution of data, is still one of the most debated disciplines in technology as evident by the plethora of standards, implementations, and permutations of transmission and storage technologies.

The 2020’s are a decade of Data Science revolution bound to defy all predictions. The mass flow of information is an impending typhoon and we have only just experienced the relative beginnings as the calm before the storm.

== Challenge is Everywhere
The world is cutting it's teeth on solving the puzzle of how to derive usefulness from the rising seas of data.

*CIOs* are charting new territory in the race to monetize data at scale. This requires understanding what data is important to them.

*Security and Operations* teams are trying to scale techniques to understand risks and safety measures required to handle data lakes and oceans as they grow beyond anything we’ve retained before. This requires trust and a comprehension of the data itself.

*Product and Developer* teams are trying to forge usefulness from data to make it tangibly relevant to living simpler, more fruitful lives. This requires context.

*Data Consumers*, individuals, organizations, businesses, and governments. The people who require data. We all seek usefulness, meaning, and inspiration when hunting for data. Likely you also, the audience of this document, also value data. Universally, when we reach out for data and query the world wide web, we usually prioritize relevance above all else.

== Perspective in Focus
At this point, opportunity is over flowing. Collectively, from all of these perspectives, we understand that when we request data, we value understanding, trust, context, and relevance.

The UOR Framework is an exercise in extracting protocol, specification, and implementation criteria from modern data solution patterns with the aim of commoditizing the value of data and delivering these core needs in an unobtrusive and reliable way.

== Inspiration Realized
Inspiration struck while creating a tool to implement precise control over data and declaratively produce useful collections of necessary data objects of all types from various internet hosted origins.

Object storage, most commonly implemented via the S3 protocol today, has dominated storage technology adoption since its release in 2006. From AWS, to other Public Clouds, on-prem integration into CEPH and other storage appliance providers. S3 has proven wildly valuable as a cornerstone of cloud adoption. Not only did the S3 standard prove to be wildly successful, it validated the impact that useful standards can have when designed to be unobtrusive and reliable.

Container technologies, famous for their rise to popularity with the release of Docker in 2013, and Kubernetes in 2014. Containers have captivated the Information Technology world’s desire for application portability and confidence. Becoming a nearly ubiquitous distribution mechanism in most software product offerings and garnering over link:https://k8s.devstats.cncf.io/d/9/companies-table?orgId=1[2,932,740 code commits from 4403 represented independent developers and corporations] since the public debut of the foundational open source software projects. Containers have proven the real world value of standardized, knowable, and predictable packages.

These two technologies have significantly influenced the inspirational process of how to wrangle diverse data types and sources, and predictably funnel them into a supply chain for exotic environments including fully air-gapped production space.

== Vision Materialized
From our perspective and inspiration, we strive to understand what establishes the value of data. Next, we wanted to understand what establishes the usefulness of data.

Ability to act on data requires what we have come to know as 4 universal elements of data.

1. The obvious first being arbitrary 'blobs' for which we will refer to them as 'objects' here. _Objects_ are the core element which we value, and what we rely on to do useful work.
2. The second element is _Origin_. We need to know how to access the data and also preferably, assurance to where the data comes from.
3. Third, are the _Attributes_ associated with the data. Understanding data attributes is vital to intelligently acting on an object.
4. Finally, the fourth element is a _Specification_. We require an understanding of how to interpret the data in some structured way to consume the content and make it intelligible.

*_Objects_*, under a strictly data focused microscope, can be represented as _any_ data. An object can be an executable blob, code or spec files, video or image media, even machine learning models, operating system images, and beyond. All of these things are data objects. This is not a novel paradigm. Developers, operations, and end users interact with digital assets every day, whether reading a blog post, running an application on your phone, or publishing new images and videos to social media. Objects are the content in data that transforms our lives once we have the data that is relevant to us.

*_Origin_* is a crucial element of data which many brilliant innovators have invented incredible technologies to solve. From DNS and IP, to PGP and SSL protocols. The world wide web is strung together by loosely coupled threads of query enabled data publishing and origin attestation technologies.

*_Attributes_* can comprise a broad scope, but can quickly be understood in the concept of an executable, where one attribute of the object is that it can be executed as code by a compute runtime, or alternatively by the analogy of an image file with included meta-data such as geo-location data and image subject matter tags. Beyond that, things like object level RBAC attributes, or distributed ledger correlation quickly surface as valuable built in context which makes data immensely more valuable.

*_Specification_* are undoubtedly the most loosely coupled of all element types. Often run-times and the specifications they demand data conformity to are distributed separately from the data itself. Executable binaries may require their runtime or dependencies to be pre-installed. Video may be distributed in formats which demand that codec dependencies be accounted for by some separate means. In just this short list, we see completely separate ecosystems inventing wheels to solve the same pattern of need for interpretation schemes, and both implementing specification publication and distribution via separate distribution models than the one(s) employed to publish and distribute the data object element itself.

== UOR Sig in Action

On this journey, we have come to believe that the usefulness of data is carried in 4 core elements of data. We have also come to understand that the value of data is measured by 4 values.

[width=70%, cols="2", frame=ends, grid=rows]
|===
| *Core Values of Data* | *Core Elements of Data*

|Trust
|Origin

|Relevance
|Object

|Understanding
|Specification

|Context
|Attributes

|===

Conventional paradigms of data distribution place the onus of establishing the 4 values of data and conveying the 4 elements of data onto separate disaggregated distribution models. These distribution models frequently vary from object type to object type, publisher to publisher, and consumption model to consumption model.

A UOR Artifact establishes the 4 values, via the 4 elements, combined as a unified standardized dataset. A self describing, trustable, knowable, and understandable object. In essence, programmable data objects. This convergence of data elements is achievable based entirely on well practiced and understood patterns of data distribution already applied in technologies such as S3 and container distribution standards.

These early days of exploring the possibility and potential of UOR has garnered reactions from collaborators and critics both, ranging from declaring the idea to be "impossible fantasy", to predicting that it will be the digital equivalent of a primordial soup destined to spontaneously generate self aware AI.

UOR Sig believes that the commoditizing the core promises of understanding, trust, context, and relevance are very achievable and the value to be exponential to adoption. With the right support of cross industry experience and imagination, implementing UOR is immediately relevant to the web 2.0 of today, and also provides a unifying framework to practically link the many exciting developments in the web 3.0 world of tomorrow.

As proof, our exploration has led to a preliminary reference model, distribution scheme, runtime implementation, and client model compatible with conventional data distribution and consumption techniques while also improved to reduce the fatigue of data manipulation experienced by developers, operations, and security teams so that resources can spend less on the juggling act and invest more confidently in the activities that promote inventive value.

The Universal Object Reference Framework seeks to bring that vision into reality.
